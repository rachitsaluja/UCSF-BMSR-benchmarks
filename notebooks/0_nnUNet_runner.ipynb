{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install nnUNet v1, and run this notebook using the nnUNet conda/virtual env. \n",
    "\n",
    "### Firstly setting up environment variables\n",
    "\n",
    "Add your path here instead and copy paste in terminal in your nnUNet Environment:\n",
    "```\n",
    "export nnUNet_raw_data_base=\"/location/to/nnUNet_raw_data_base\"\n",
    "export nnUNet_preprocessed=\"/location/to/nnUNet_preprocessed\"\n",
    "export RESULTS_FOLDER=\"/location/to/nnUNet_trained_models\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Transferring of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from natsort import natsorted\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnUnet_transfer_images(patients_dir, list_of_modalities, output_dir, exp_name):\n",
    "    all_patients_dir = natsorted(glob(patients_dir + '/*'))\n",
    "    \n",
    "    for i, p in enumerate(all_patients_dir):\n",
    "        for j, modality in enumerate(list_of_modalities):\n",
    "            src_file = p + '/' + p.split('/')[-1] + '_' + modality + '.nii.gz'\n",
    "            dst_file = output_dir + '/' + exp_name + '_' + '{:04}'.format(i+1) + '_000' + str(j) + '.nii.gz' \n",
    "\n",
    "            #print(dst_file)\n",
    "            os.system('cp -r '+ src_file + ' ' + dst_file)    \n",
    "            \n",
    "def nnUnet_transfer_segs(patients_dir, output_dir, exp_name):\n",
    "    \n",
    "    all_patients_dir = natsorted(glob(patients_dir + '/*'))\n",
    "    \n",
    "    for i, p in enumerate(all_patients_dir):\n",
    "        src_file = p + '/' + p.split('/')[-1] + '_seg.nii.gz'\n",
    "        dst_file = output_dir + '/' + exp_name + '_'  + '{:04}'.format(i+1) + '.nii.gz'\n",
    "\n",
    "        #print(dst_file)\n",
    "        os.system('cp -r '+ src_file + ' ' + dst_file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Files directory\n",
    "\n",
    "Change the experiment name and path for your project/experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('mkdir /location/to/TaskXXX_UCSF_BMSR')\n",
    "os.system('mkdir /location/to/TaskXXX_UCSF_BMSR/imagesTr')\n",
    "os.system('mkdir /location/to/TaskXXX_UCSF_BMSR/imagesTs')\n",
    "os.system('mkdir /location/to/TaskXXX_UCSF_BMSR/labelsTr')\n",
    "os.system('mkdir /location/to/TaskXXX_UCSF_BMSR/labelsTs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transferring Images\n",
    "\n",
    "Change the experiment name and path for your project/experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUnet_transfer_images(patients_dir = '/location/to/patients_1/', \n",
    "                     list_of_modalities = ['flair','t1','t2'], \n",
    "                     output_dir = '/location/to/TaskXXX_UCSF_BMSR/imagesTr', \n",
    "                     exp_name = 'TrialExp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUnet_transfer_images(patients_dir = '/location/to/patients_2/', \n",
    "                     list_of_modalities = ['flair','t1','t2'], \n",
    "                     output_dir = '/location/to/TaskXXX_UCSF_BMSR/imagesTs', \n",
    "                     exp_name = 'TrialExp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transferring Segs\n",
    "\n",
    "Change the experiment name and path for your project/experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUnet_transfer_segs(patients_dir = '/location/to/patients_1/', \n",
    "                     output_dir = '/location/to/TaskXXX_UCSF_BMSR/labelsTr', \n",
    "                     exp_name = 'TrialExp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUnet_transfer_segs(patients_dir = '/location/to/patients_2/', \n",
    "                     output_dir = '/location/to/TaskXXX_UCSF_BMSR/labelsTs', \n",
    "                     exp_name = 'TrialExp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataset json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from batchgenerators.utilities.file_and_folder_operations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers_from_splitted_files(folder: str):\n",
    "    uniques = np.unique([i[:-12] for i in subfiles(folder, suffix='.nii.gz', join=False)])\n",
    "    return uniques\n",
    "\n",
    "\n",
    "def generate_dataset_json(output_file: str, imagesTr_dir: str, imagesTs_dir: str, modalities: Tuple,\n",
    "                          labels: dict, dataset_name: str, license: str = \"hands off!\", dataset_description: str = \"\",\n",
    "                          dataset_reference=\"\", dataset_release='0.0'):\n",
    "    \"\"\"\n",
    "    :param output_file: This needs to be the full path to the dataset.json you intend to write, so\n",
    "    output_file='DATASET_PATH/dataset.json' where the folder DATASET_PATH points to is the one with the\n",
    "    imagesTr and labelsTr subfolders\n",
    "    :param imagesTr_dir: path to the imagesTr folder of that dataset\n",
    "    :param imagesTs_dir: path to the imagesTs folder of that dataset. Can be None\n",
    "    :param modalities: tuple of strings with modality names. must be in the same order as the images (first entry\n",
    "    corresponds to _0000.nii.gz, etc). Example: ('T1', 'T2', 'FLAIR').\n",
    "    :param labels: dict with int->str (key->value) mapping the label IDs to label names. Note that 0 is always\n",
    "    supposed to be background! Example: {0: 'background', 1: 'edema', 2: 'enhancing tumor'}\n",
    "    :param dataset_name: The name of the dataset. Can be anything you want\n",
    "    :param license:\n",
    "    :param dataset_description:\n",
    "    :param dataset_reference: website of the dataset, if available\n",
    "    :param dataset_release:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_identifiers = get_identifiers_from_splitted_files(imagesTr_dir)\n",
    "\n",
    "    if imagesTs_dir is not None:\n",
    "        test_identifiers = get_identifiers_from_splitted_files(imagesTs_dir)\n",
    "    else:\n",
    "        test_identifiers = []\n",
    "\n",
    "    json_dict = {}\n",
    "    json_dict['name'] = dataset_name\n",
    "    json_dict['description'] = dataset_description\n",
    "    json_dict['tensorImageSize'] = \"4D\"\n",
    "    json_dict['reference'] = dataset_reference\n",
    "    json_dict['licence'] = license\n",
    "    json_dict['release'] = dataset_release\n",
    "    json_dict['modality'] = {str(i): modalities[i] for i in range(len(modalities))}\n",
    "    json_dict['labels'] = {str(i): labels[i] for i in labels.keys()}\n",
    "\n",
    "    json_dict['numTraining'] = len(train_identifiers)\n",
    "    json_dict['numTest'] = len(test_identifiers)\n",
    "    json_dict['training'] = [\n",
    "        {'image': \"./imagesTr/%s.nii.gz\" % i, \"label\": \"./labelsTr/%s.nii.gz\" % i} for i\n",
    "        in\n",
    "        train_identifiers]\n",
    "    json_dict['test'] = [\"./imagesTs/%s.nii.gz\" % i for i in test_identifiers]\n",
    "\n",
    "    if not output_file.endswith(\"dataset.json\"):\n",
    "        print(\"WARNING: output file name is not dataset.json! This may be intentional or not. You decide. \"\n",
    "              \"Proceeding anyways...\")\n",
    "    save_json(json_dict, os.path.join(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset_json(\n",
    "    output_file = \"/location/to/TaskXXX_UCSF_BMSR/dataset.json\",\n",
    "    imagesTr_dir = \"/location/to/TaskXXX_UCSF_BMSR/imagesTr\",\n",
    "    imagesTs_dir = \"/location/to/TaskXXX_UCSF_BMSR/imagesTs\",\n",
    "    modalities = ('flair', 't1', 't2'),\n",
    "    labels = {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"FLAIR abnormal singal\"\n",
    "    },\n",
    "    dataset_name = \"Trialexp\",\n",
    "    license = \"hands off!\",\n",
    "    dataset_description = \"nnUnet experiment for Trialexp\",\n",
    "    dataset_reference = \"\",\n",
    "    dataset_release = \"1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run Preprocessing\n",
    "\n",
    "\n",
    "Copy and run this on the terminal.\n",
    "\n",
    "```\n",
    "nnUNet_plan_and_preprocess -t XXX --verify_dataset_integrity\n",
    "```\n",
    "\n",
    "If everything is okay, then it will automatically run preprocessing. If not, there could be errors in your image and seg size then you need to fix it. OR if there is some small orientation differences also, it won't run automatically, here you can still do preprocessing by running the following\n",
    "\n",
    "```\n",
    "nnUNet_plan_and_preprocess -t XXX \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run training\n",
    "\n",
    "To run the training run the following on the terminal\n",
    "\n",
    "```\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNet_train 3d_fullres nnUNetTrainerV2 TaskXXX_MYTASK FOLD --npz\n",
    "```\n",
    "\n",
    "FOLD = 0,1,2,3,4,all\n",
    "\n",
    "To stop training anytime, just press CTRL-C\n",
    "\n",
    "To start again\n",
    "```\n",
    "nnUNet_train 3d_fullres nnUNetTrainerV2 TaskXXX_MYTASK FOLD --npz -c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Inference\n",
    "\n",
    "To run the inference run the following on the terminal\n",
    "\n",
    "```\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNet_predict -i /location/to/TaskXXX_UCSF_BMSR/imagesTs -o /location/to/TaskXXX_UCSF_BMSR/imagesTs_pred -t XXX -m 3d_fullres -f all --save_npz \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
