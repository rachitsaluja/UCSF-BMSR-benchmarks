{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install nnUNet from https://github.com/rixez/Brats21_KAIST_MRI_Lab, and run this notebook using the nnUNet conda/virtual env. \n",
    "\n",
    "### Firstly setting up environment variables\n",
    "\n",
    "Add your path here instead and copy paste in terminal in your nnUNet Environment:\n",
    "```\n",
    "export nnUNet_raw_data_base=\"/location/to/nnUNet_raw_data_base\"\n",
    "export nnUNet_preprocessed=\"/location/to/nnUNet_preprocessed\"\n",
    "export RESULTS_FOLDER=\"/location/to/nnUNet_trained_models\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brats 2021 nnUNet inference\n",
    "\n",
    "\n",
    "Make sure your data is in the form of:\n",
    "\n",
    "`'modalities': {0: 'T1', 1: 'T1ce', 2: 'T2', 3: 'FLAIR'}`\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "1. BraTS2021_00621_0000.nii.gz\n",
    "2. BraTS2021_00621_0001.nii.gz\n",
    "3. BraTS2021_00621_0002.nii.gz\n",
    "4. BraTS2021_00621_0003.nii.gz\n",
    "\n",
    "5. BraTS2021_00622_0000.nii.gz\n",
    "6. BraTS2021_00622_0001.nii.gz\n",
    "7. BraTS2021_00622_0002.nii.gz\n",
    "8. BraTS2021_00622_0003.nii.gz\n",
    "```\n",
    "\n",
    "Download the model from `https://drive.google.com/file/d/1yWgD1JlEocXRWVMAYOa7YKtQLEhDjhIx/view?usp=sharing`. Extract the model from the rar file and open the directory and go into `3d_fullres`. \n",
    "\n",
    "copy that and paste into `/location/to/nnUNet_trained_models/nnUNet/3d_fullres/`\n",
    "\n",
    "so now it should be \n",
    "\n",
    "`/location/to/nnUNet_trained_models/nnUNet/3d_fullres/Task500_BraTS2021`\n",
    "\n",
    "\n",
    "Basically you are placing the 3d inference model where all the model should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Transferring of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from natsort import natsorted\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnUnet_transfer_images(patients_dir, list_of_modalities, output_dir, exp_name):\n",
    "    all_patients_dir = natsorted(glob(patients_dir + '/*'))\n",
    "    \n",
    "    for i, p in enumerate(all_patients_dir):\n",
    "        for j, modality in enumerate(list_of_modalities):\n",
    "            src_file = p + '/' + p.split('/')[-1] + '_' + modality + '.nii.gz'\n",
    "            dst_file = output_dir + '/' + exp_name + '_' + '{:04}'.format(i+1) + '_000' + str(j) + '.nii.gz' \n",
    "\n",
    "            #print(dst_file)\n",
    "            os.system('cp -r '+ src_file + ' ' + dst_file)    \n",
    "            \n",
    "def nnUnet_transfer_segs(patients_dir, output_dir, exp_name):\n",
    "    \n",
    "    all_patients_dir = natsorted(glob(patients_dir + '/*'))\n",
    "    \n",
    "    for i, p in enumerate(all_patients_dir):\n",
    "        src_file = p + '/' + p.split('/')[-1] + '_seg.nii.gz'\n",
    "        dst_file = output_dir + '/' + exp_name + '_'  + '{:04}'.format(i+1) + '.nii.gz'\n",
    "\n",
    "        #print(dst_file)\n",
    "        os.system('cp -r '+ src_file + ' ' + dst_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('mkdir /location/to/Task500_BraTS2021')\n",
    "os.system('mkdir /location/to/Task500_BraTS2021/imagesTr')\n",
    "os.system('mkdir /location/to/Task500_BraTS2021/labelsTr')\n",
    "os.system('mkdir /location/to/Task500_BraTS2021/imagesTs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer images: (To get into format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUnet_transfer_images(patients_dir = '/media/data/BraTS2021/', \n",
    "                     list_of_modalities = ['t1','t1ce','t2','flair'], \n",
    "                     output_dir = '/location/to/Task500_BraTS2021/imagesTr', \n",
    "                     exp_name = 'BraTS2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer segs: (To get into format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUnet_transfer_segs(patients_dir = '/media/data/BraTS2021/', \n",
    "                     output_dir = '/location/to/Task500_BraTS2021/labelsTr', \n",
    "                     exp_name = 'BraTS2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataset JSON (Incase of Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from batchgenerators.utilities.file_and_folder_operations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers_from_splitted_files(folder: str):\n",
    "    uniques = np.unique([i[:-12] for i in subfiles(folder, suffix='.nii.gz', join=False)])\n",
    "    return uniques\n",
    "\n",
    "\n",
    "def generate_dataset_json(output_file: str, imagesTr_dir: str, imagesTs_dir: str, modalities: Tuple,\n",
    "                          labels: dict, dataset_name: str, license: str = \"hands off!\", dataset_description: str = \"\",\n",
    "                          dataset_reference=\"\", dataset_release='0.0'):\n",
    "    \"\"\"\n",
    "    :param output_file: This needs to be the full path to the dataset.json you intend to write, so\n",
    "    output_file='DATASET_PATH/dataset.json' where the folder DATASET_PATH points to is the one with the\n",
    "    imagesTr and labelsTr subfolders\n",
    "    :param imagesTr_dir: path to the imagesTr folder of that dataset\n",
    "    :param imagesTs_dir: path to the imagesTs folder of that dataset. Can be None\n",
    "    :param modalities: tuple of strings with modality names. must be in the same order as the images (first entry\n",
    "    corresponds to _0000.nii.gz, etc). Example: ('T1', 'T2', 'FLAIR').\n",
    "    :param labels: dict with int->str (key->value) mapping the label IDs to label names. Note that 0 is always\n",
    "    supposed to be background! Example: {0: 'background', 1: 'edema', 2: 'enhancing tumor'}\n",
    "    :param dataset_name: The name of the dataset. Can be anything you want\n",
    "    :param license:\n",
    "    :param dataset_description:\n",
    "    :param dataset_reference: website of the dataset, if available\n",
    "    :param dataset_release:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_identifiers = get_identifiers_from_splitted_files(imagesTr_dir)\n",
    "\n",
    "    if imagesTs_dir is not None:\n",
    "        test_identifiers = get_identifiers_from_splitted_files(imagesTs_dir)\n",
    "    else:\n",
    "        test_identifiers = []\n",
    "\n",
    "    json_dict = {}\n",
    "    json_dict['name'] = dataset_name\n",
    "    json_dict['description'] = dataset_description\n",
    "    json_dict['tensorImageSize'] = \"4D\"\n",
    "    json_dict['reference'] = dataset_reference\n",
    "    json_dict['licence'] = license\n",
    "    json_dict['release'] = dataset_release\n",
    "    json_dict['modality'] = {str(i): modalities[i] for i in range(len(modalities))}\n",
    "    json_dict['labels'] = {str(i): labels[i] for i in labels.keys()}\n",
    "\n",
    "    json_dict['numTraining'] = len(train_identifiers)\n",
    "    json_dict['numTest'] = len(test_identifiers)\n",
    "    json_dict['training'] = [\n",
    "        {'image': \"./imagesTr/%s.nii.gz\" % i, \"label\": \"./labelsTr/%s.nii.gz\" % i} for i\n",
    "        in\n",
    "        train_identifiers]\n",
    "    json_dict['test'] = [\"./imagesTs/%s.nii.gz\" % i for i in test_identifiers]\n",
    "\n",
    "    if not output_file.endswith(\"dataset.json\"):\n",
    "        print(\"WARNING: output file name is not dataset.json! This may be intentional or not. You decide. \"\n",
    "              \"Proceeding anyways...\")\n",
    "    save_json(json_dict, os.path.join(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset_json(\n",
    "    output_file = \"/location/to/Task500_BraTS2021/dataset.json\",\n",
    "    imagesTr_dir = \"/location/to/Task500_BraTS2021/imagesTr\",\n",
    "    imagesTs_dir = \"/location/to/Task500_BraTS2021/imagesTs\",\n",
    "    modalities = ('t1', 't1ce', 't2', 'flair'),\n",
    "    labels = {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"Class 1\",\n",
    "        \"2\": \"Class 2\",\n",
    "        \"3\": \"Class 3\"\n",
    "    },\n",
    "    dataset_name = \"Brats Training\",\n",
    "    license = \"hands off\",\n",
    "    dataset_description = \"nnUnet experiment for Brats2021\",\n",
    "    dataset_reference = \"\",\n",
    "    dataset_release = \"1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Try Inference\n",
    "\n",
    "You can transfer some images in a folder to try inference\n",
    "\n",
    "Using Model 1\n",
    "```\n",
    "nnUNet_predict -i <input_folder> -o <output_folder1> -t 500 -m 3d_fullres -tr nnUNetTrainerV2BraTSRegions_DA4_BN_BD --save_npz\n",
    "```\n",
    "Using Model 2\n",
    "```\n",
    "nnUNet_predict -i <input_folder> -o <output_folder2> -t 500 -m 3d_fullres -tr nnUNetTrainerV2BraTSRegions_DA4_BN_BD_largeUnet_Groupnorm --save_npz\n",
    "```\n",
    "\n",
    "Using Ensemble Model\n",
    "```\n",
    "nnUNet_ensemble -f <output_folder1> <output_folder2> -o <final_output_folder>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fine-tuning the model\n",
    "\n",
    "\n",
    "Similar to the Transfer learning Notebook I sent\n",
    "\n",
    "#### Preprocessing:\n",
    "\n",
    "Example:\n",
    "\n",
    "A - \n",
    "```\n",
    "nnUNet_plan_and_preprocess -t 501 -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans /media/rnd/nnUNet/RESULTS_FOLDER/nnUNet/3d_fullres/Task500_BraTS2021/nnUNetTrainerV2BraTSRegions_DA4_BN_BD_largeUnet_Groupnorm__nnUNetPlansv2.1/plans.pkl -overwrite_plans_identifier GROUP_NORM_FT\n",
    "```\n",
    "\n",
    "B - \n",
    "\n",
    "```\n",
    "nnUNet_plan_and_preprocess -t 501 -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans /media/rnd/nnUNet/RESULTS_FOLDER/nnUNet/3d_fullres/Task500_BraTS2021/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1/plans.pkl -overwrite_plans_identifier OTHER_FT\n",
    "```\n",
    "\n",
    "#### Training:\n",
    "\n",
    "And now that we have processed the data into the version of the model we need to fine tune. We just need to train. Which is a little different but similar:\n",
    "\n",
    "```\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNet_train 3d_fullres nnUNetTrainerV2 Task501_BraTS2021 all -p nnUNetPlans_pretrained_GROUP_NORM_FT --npz -pretrained_weights /media/rnd/nnUNet/RESULTS_FOLDER/nnUNet/3d_fullres/Task500_BraTS2021/nnUNetTrainerV2BraTSRegions_DA4_BN_BD_largeUnet_Groupnorm__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
